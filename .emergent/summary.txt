<analysis>**original_problem_statement:**
You are a senior product architect, full-stack engineer, UX designer, and privacy-by-design specialist. Your task is to design and implement a fully functional MVP platform named PubProcess.

PRODUCT REQUIREMENTS:
The platform's purpose has evolved from a simple channel for editorial decision complaints to a broad, neutral platform for evaluating the entire editorial process. It should be used by authors with positive, neutral, and negative experiences.

Core features to implement/refine:
1.  **Conditional Submission Form:** The submission form logic must be refined to prevent logical contradictions. For example, questions about the quality of editor comments should only appear if the user indicates that comments were provided.
2.  **Hierarchical Scientific Areas:** The Scientific Area field must be restructured into a hierarchical, chained-dropdown system (Grande Área → Área → Subárea) based on the official CNPq table of knowledge areas (data already extracted from a user-provided PDF).
3.  **Admin Area Management:** Admins must be able to manage the new hierarchical areas (edit, activate/deactivate, create analytical groupings).
4.  **Data Governance:** Submissions must be flagged as  based on completeness, logical consistency, and non-duplication. Only valid submissions should feed into public, aggregated metrics.
5.  **Controlled Data Visibility:** The platform must support three data visibility modes, controllable by an admin: User-Only Insights, Threshold-Based Public Statistics (e.g., ≥3 submissions from ≥3 users per journal), and Admin-Forced Public Visibility.
6.  **Neutral Metrics:** The platform should calculate and display aggregated, neutral scores like Average Review Quality and Decision Fairness Index, avoiding competitive rankings. The number of evaluations for a metric should be hidden until a high threshold (e.g., 400) is met.
7.  **Institutional Tone:** All user-facing communication (banners, empty states) must be professional, neutral, and methodologically responsible, avoiding language that suggests the platform is empty or in testing.

**User's preferred language**: Portuguese. The user communicates in both English and Portuguese, but the most recent detailed requests have been in Portuguese. The agent should prioritize responding in Portuguese.

**what currently exists?**
A full-stack application (React, FastAPI, MongoDB) with a complete feature set for the PubProcess platform. This includes:
- User authentication via Google and a now-functional ORCID OAuth 2.0 flow.
- A multi-step submission form that has been recently expanded to include new quality assessment fields.
- A comprehensive admin dashboard with controls for moderating submissions and managing platform-wide data visibility settings (User-only, Threshold-based, Demo mode).
- A public analytics page that conditionally displays aggregated statistics or a data collection in progress banner based on admin settings.
- A user dashboard that displays personal, aggregated insights from their own submissions.
- Backend logic for flagging sample data and ensuring it's excluded from real analytics.
- A  flag has been added to submissions, though the logic is still basic.
- New aggregated quality scores (e.g., Average Review Quality, Fairness Index) are calculated in the backend and displayed on the analytics page.

**Last working item**:
- **Last item agent was working:** The agent was preparing to implement the user's latest request for conditional form logic and a hierarchical scientific area selection. The last action was successfully extracting the hierarchical data from the user-provided  file. The agent was about to present the implementation plan.
- **Status:** NOT STARTED (Implementation of the new feature has not begun, only the preparatory data extraction).
- **Agent Testing Done:** N/A
- **Which testing method agent to use?** both
- **User Testing Done:** N

**All Pending/In progress Issue list**:
- **Issue 1 (P0):** Implement conditional logic in the submission form.
- **Issue 2 (P1):** The automated screenshot test for the admin dashboard () is failing.
- **Issue 3 (P2):** Implement optional account linking for users who sign in with both Google and ORCID.

**Issues Detail:**
- **Issue 1:** Implement conditional logic in the submission form.
    - **Attempted fixes:** None. This is part of the next feature request.
    - **Next debug checklist:**
        1.  Identify all fields in  that should be conditional (e.g., APC questions based on Open Access choice, editor comment quality based on comment existence).
        2.  Implement state-driven conditional rendering in the React component for these fields.
        3.  Update the backend validation in  to ensure that data for conditional fields is only accepted when the parent condition is met.
        4.  Update the  logic to account for these new consistency rules.
    - **Why fix this issue and what will be achieved with the fix?** To improve data quality by preventing users from submitting logically inconsistent or contradictory information, which strengthens the platform's methodological rigor.
    - **Status:** NOT STARTED
    - **Is recurring issue?** N
    - **Should Test frontend/backend/both after fix?** both
    - **Blocked on other issue:** None

- **Issue 2:** Admin dashboard screenshot test failure.
    - **Attempted fixes:** None. This issue was identified in the initial handoff from a previous fork and was dismissed by that agent. The current agent did not address it.
    - **Next debug checklist:**
        1.  Examine the testing agent's Playwright script that is used for automated tests.
        2.  The failure is likely due to the test navigating to  before an authentication state (cookie/token) is established, causing a redirect to the login page.
        3.  Modify the test script to properly authenticate *before* navigating to the admin page.
    - **Why fix this issue and what will be achieved with the fix?** To restore automated test coverage for the admin UI, ensuring that future changes do not break its functionality or appearance.
    - **Status:** NOT STARTED
    - **Is recurring issue?** Y (Carried over from a previous session)
    - **Should Test frontend/backend/both after fix?** frontend
    - **Blocked on other issue:** None

- **Issue 3:** Implement optional account linking.
    - **Attempted fixes:** None.
    - **Next debug checklist:**
        1.  Design backend logic to detect when a new login (e.g., via ORCID) corresponds to an existing user based on a shared identifier (like a verified email, if available from both providers).
        2.  Create a UI prompt asking the user if they wish to link the accounts.
        3.  Update the  collection to store multiple provider identifiers under a single user profile.
    - **Why fix this issue and what will be achieved with the fix?** To prevent duplicate user accounts, improve user experience, and ensure data integrity by consolidating all submissions from a single individual.
    - **Status:** NOT STARTED
    - **Is recurring issue?** N
    - **Should Test frontend/backend/both after fix?** both
    - **Blocked on other issue:** None

**In progress Task List**:
- **Task 1:** Implement hierarchical scientific area selection.
    - **Where to resume:** Use the data extracted from  to build the new selection UI and backend logic.
    - **What will be achieved with this?** A more structured and scientifically rigorous data entry process for the user's field of research, enabling more granular future analysis.
    - **Status:** IN PROGRESS (Data has been extracted, implementation is next).
    - **Should Test frontend/backend/both after fix?** both
    - **Blocked on something:** None.

**Upcoming and Future Tasks**
- **Upcoming Tasks:**
    - (P1) Create admin controls for managing the new hierarchical scientific areas (editing, activating/deactivating).
    - (P1) Refine the  logic to be more robust, checking for incompleteness, logical inconsistency, and simple duplicates.
- **Future Tasks:**
    - (P2) Add email notifications to users when their submissions are validated or flagged.
    - (P2) Implement a feature for users or admins to export analytics data as CSV/JSON.
    - (P2) Automate the verification process for user-added journals.
    - (P2) Implement a feature to compare 2-3 journals side-by-side based on quality indices.

**Completed work in this session**
- **ORCID OAuth 2.0 Fix:** Resolved a critical  error by re-architecting the  generation to be absolute and environment-driven, fixing the entire ORCID login flow.
- **Controlled Data Visibility System:** Implemented a full-featured system allowing admins to control data visibility (User-Only, Threshold-Based, Admin-Forced), manage sample data via a Demo Mode, and purge test data. The frontend UI (admin panel, banners) and all backend analytics endpoints were updated accordingly.
- **Platform Repositioning (Phase 1):** Evolved the platform towards a neutral evaluation tool by:
    - Adding new quality-focused fields to the submission form (, , , ).
    - Creating and displaying new aggregated quality indices on the analytics page.
    - Updating the user-facing messaging to have a more institutional and methodologically sound tone.
    - All changes were verified by the testing agent.

**Earlier issues found/mentioned but not fixed**
- **Issue 1:** Admin dashboard screenshot test failure.
    - **Debug checklist:** Investigate the testing agent's authentication process within its test scripts. The test likely needs to set an auth cookie before navigating to the  page.
    - **Why to solve this issue and what will be achieved with this?** Fixing this will ensure the admin dashboard's UI is included in the automated regression testing suite.
    - **Should Test frontend/backend/both after fix:** frontend
    - **Is recurring issue?** Y

**Known issue recurrence from previous fork**
- None.

**Code Architecture**


**Key Technical Concepts**
- **Frontend:** React, Tailwind CSS, 
- **Backend:** FastAPI, Pydantic, Motor (async MongoDB driver)
- **Database:** MongoDB
- **Authentication:** Session tokens in cookies, Emergent-managed Google OAuth, ORCID OAuth 2.0.
- **Architecture:** Decoupled SPA/REST API. The backend logic has grown to include a settings management system that controls data visibility across the application.

**key DB schema**
- **platform_settings:**  (New collection)
- **submissions:** Now includes , , and new quality fields (, , etc.).  will be refactored.
- **users, sessions, journals, publishers:** No major changes.

**changes in tech stack**
- None.

**All files of reference**
- : Heavily modified to add visibility logic, new admin endpoints, new quality assessment fields/indices, and the ORCID fix. Refactoring is critical.
- : Updated to flag all sample data with  and populate new quality assessment fields.
- : Updated with a new Settings tab for managing platform visibility and data.
- : A new Quality Assessment step was added, increasing the total steps from 5 to 6.
- : Reworked to conditionally show statistics or a visibility banner, and to display the new quality indices.
- : Updated to show a Personal Insights section based on the user's own submission data.
- : New reusable component for displaying visibility notices.

**Areas that need refactoring**:
-  is now a massive monolith (over 1400 lines). It urgently needs to be broken down into a more maintainable structure (e.g., , , , ). The current state makes adding new features risky and time-consuming.

**key api endpoints**
- :  and  endpoints to manage platform visibility settings.
- :  endpoint to delete all sample data.
- :  endpoint to retrieve personal aggregated stats for the logged-in user.
- : New  endpoints for the new quality assessment form fields.
- : Endpoint fixed to use an absolute, environment-driven .
- Analytics endpoints (): All have been updated to respect the new data visibility rules.

**Critical Info for New Agent**
- **Prioritize User's Plan:** The user has laid out a clear, multi-part task. The immediate priority is implementing the hierarchical Scientific Area selection using the already-extracted CNPq data, followed by adding conditional logic to the form.
- **Refactor :** After the current feature is complete, you should strongly propose and prioritize refactoring the monolithic  file. Its current size is a significant technical debt.
- **Unfixed Admin Test:** The failing automated test for the  page screenshot has been ignored for two sessions. It should be investigated and fixed to ensure complete test coverage.
- **Data for Areas:** The hierarchical data for the new scientific area feature has been extracted from the user's PDF and is ready for use. You do not need to re-extract it.

**documents and test reports created in this job**
- 
- 
- 
-  (updated multiple times)

**Last 10 User Messages and any pending HUMAN messages**
1.  **User (latest):** Requested form refinements (conditional logic for APC/editor comments) and a complete overhaul of the Scientific Area field to a hierarchical structure based on an attached PDF (CNPq table). (IN PROGRESS)
2.  **Agent:** Finished implementing the platform repositioning (new quality fields, scores, and institutional tone).
3.  **User:** Approved the plan to reposition the platform, providing specific new form fields, aggregated scores, and a clear implementation priority (Form → Validation → Messaging → Admin). (COMPLETED)
4.  **Agent:** Asked for clarification on the broad evaluation platform request, proposing new fields and scores.
5.  **User:** Requested a major evolution of the platform from a complaint channel to a broad and neutral evaluation platform, detailing requirements for metrics, data validity, and user communication. (COMPLETED)
6.  **Agent:** Finished implementing the controlled data visibility system.
7.  **User:** Approved the plan for the data visibility system, suggesting some consolidation to improve efficiency. (COMPLETED)
8.  **Agent:** Proposed a detailed plan to implement the data visibility system after exploring the codebase.
9.  **User:** Requested the implementation of a sophisticated, controlled data visibility system (User-Only, Threshold-Based, Admin-Forced modes) and an admin control panel. (COMPLETED)
10. **Agent:** Confirmed the fix for the ORCID  bug was applied and asked the user to test again.

**Project Health Check:**
- **Broken:** No core features are currently broken. The ORCID login issue has been resolved.
- **Mocked:** No application features are mocked.

**3rd Party Integrations**
- **Emergent-managed Google Auth:** Integrated and functional.
- **ORCID OAuth 2.0:** Integrated, functional, and production-ready after a critical bug fix. Requires User API Key (Client ID and Secret), which have been provided and are in .
- **CNPq Area Data:** The agent has extracted data from a user-provided PDF for an upcoming feature. This is not a live integration.

**Testing status**
- **Testing agent used after significant changes:** YES. Used successfully three times in this session to validate major features.
- **Troubleshoot agent used after agent stuck in loop:** NO
- **Test files created:** The testing agent added/updated its own test scripts, but no new persistent test files (e.g., PyTest) were created in the main codebase.
- **Known regressions:** The screenshot test for the  page is still failing from a previous session.

**Credentials to test flow:**
- **Admin User:**  has admin privileges.
- **ORCID:** Credentials are in  and the flow is functional.

**What agent forgot to execute**
- The agent completely overlooked the known failing test for the admin page screenshot, which was explicitly mentioned in the initial handoff summary. It was neither fixed nor added to the plan for future work.</analysis>
